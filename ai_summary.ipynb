{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c2242b",
   "metadata": {},
   "source": [
    "# Riassunto AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b8762",
   "metadata": {},
   "source": [
    "## Agenti intelligenti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa27a34",
   "metadata": {},
   "source": [
    "### Agenti razionali"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df7b33",
   "metadata": {},
   "source": [
    "**Agente**: un sistema che percepisce il suo ambiente attraverso dei **sensori** e agisce su di esso mediante degli **attuatori**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83592b3",
   "metadata": {},
   "source": [
    "**Percezione**: input percettivi in un dato istante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d9b04",
   "metadata": {},
   "source": [
    "**Sequence percettiva**: la storia completa di tutto quello che l'agente ha percepito nella sua esistenza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510b74b",
   "metadata": {},
   "source": [
    "**Funzione agente**: funzione matematica astratta che descrive il comportamento di un agente (descrive la corrispondenza tra una qualsiasi sequenza percettiva e una specifica azione)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015c745",
   "metadata": {},
   "source": [
    "**Programma agente**: implementazione concreta della funzione agente, prende in input la percezione corrente dei sensori e restituisce un'azione agli attuatori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae36c5",
   "metadata": {},
   "source": [
    "**Autonomia**: quando un agente NON si basa sulla conoscenza pregressa inserita dal programmatore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d985b11",
   "metadata": {},
   "source": [
    "**Misure di prestazione**: valutano una sequenza di stati dell'ambiente. Vanno progettate in base all'effetto che si desidera ottenere sull'ambiente invece di su come si pensa che debba comportarsi l'ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26bd5e",
   "metadata": {},
   "source": [
    "In un dato istante, ciò che è razionale dipende da:\n",
    "- la misura di prestazione che definisce il criterio di successo\n",
    "- la conoscenza pregressa dell'ambiente da parte dell'agente\n",
    "- le azioni che l'agente può effettuare\n",
    "- la sequenza percettiva dell'agente fino all'istante corrente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7b61e6",
   "metadata": {},
   "source": [
    "**Agente razionale**: per ogni possibile sequenza di percezioni, sceglie un'azione che massimizzi il valore atteso della sua misura di prestazione, date le informazioni fornite dalla sequenza percettiva e da ogni ulteriore conoscenza dell'agente.\n",
    "\n",
    "Non si limita a raccogliere informazioni, ma deve anche essere in grado di apprendere il più possibile sulla base delle proprie percezioni per compensare la sua iniziale conoscenza parziale o erronea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae2b524",
   "metadata": {},
   "source": [
    "![image.png](images/agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b27c441",
   "metadata": {},
   "source": [
    "### La struttura degli agenti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f2d14",
   "metadata": {},
   "source": [
    "#### Agenti reattivi semplici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db1abc",
   "metadata": {},
   "source": [
    "- Scelgono le azioni sulla base della percezione corrente, ignorando tutta la storia percettiva\n",
    "- sono basati su regole condizione-azione (**if** condizione **then** azione)\n",
    "- l'**ambiente** deve essere **completamente osservabile**, anche una minima parte di non-osservabilità può causare grandi problemi\n",
    "- spesso non sono in grado di evitare cicli infiniti quando operano in ambienti parzialmente osservabili, questo si può risolvere randomizzando talvolta le azioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825822f9",
   "metadata": {},
   "source": [
    "![image.png](images/agent_reactive_simple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eefb57",
   "metadata": {},
   "source": [
    "#### Agenti reattivi basati su modello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ccea79",
   "metadata": {},
   "source": [
    "- per gestire l'osservabilità parziale si può tener traccia della parte del mondo che non si può vedere nell'istante corrente\n",
    "- quindi l'agente mantiene uno **stato interno** che dipende dalla storia delle percezioni\n",
    "- possiede 2 tipi di conoscenza:\n",
    "    - informazioni sull'evoluzione del mondo indipendentemente dalle sue azioni\n",
    "    - informazioni sull'effetto delle sue azioni sul mondo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239d8ca",
   "metadata": {},
   "source": [
    "![image.png](images/agent_reactive_model_based.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a71fe7",
   "metadata": {},
   "source": [
    "#### Agenti basati su obiettivi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e50955",
   "metadata": {},
   "source": [
    "- oltre a tener traccia dello stato dell'ambiente, memorizza un insieme di obiettivi e sceglie l'azione che lo porterà (prima o poi) a soddisfarli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d984d0",
   "metadata": {},
   "source": [
    "![image.png](images/agent_objective_based.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fde382",
   "metadata": {},
   "source": [
    "#### Agenti basati sull'utilità"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ca7db",
   "metadata": {},
   "source": [
    "- **funzione di utilità**: è un internazionalizzazione della misura di prestazione\n",
    "- sceglie l'azione che massimizza l'utilità attesa dei risultati, ovvero l'utilità che l'agente si attende di ottenere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc850b",
   "metadata": {},
   "source": [
    "![image.png](images/agent_utility_based.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf238246",
   "metadata": {},
   "source": [
    "#### Agenti capaci di apprendere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280ad02",
   "metadata": {},
   "source": [
    "- diviso in 4 componenti:\n",
    "    - **elemento esecutivo**: si occupa della selezione delle azioni esterne, equivale agli agenti descritti precedentemente\n",
    "    - **elemento critico**: dice all'elemento di apprendimento come si sta comportando l'agente rispetto ad uno standard di prestazione prefissato. E' necessario perchè di per se le percezioni non forniscono alcuna indicazione del successo dell'agente\n",
    "    - **elemento di apprendimento**: responsabile del miglioramento interno, utilizza le informazioni provenienti dall'elemento critico riguardo le prestazioni correnti dell'agente e determina se e come modificare l'elemento esecutivo affinchè in futuro si comporti meglio. Può modificare uno qualsiasi dei componenti \"di conoscenza\" mostrati nei diagrammi precedenti\n",
    "    - **generatore di problemi**: suggerisce le azioni che portino ad esperienze nuove e significative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ff367",
   "metadata": {},
   "source": [
    "![image.png](images/agent_capable_learn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb307d44",
   "metadata": {},
   "source": [
    "### Ambienti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0fb76",
   "metadata": {},
   "source": [
    "- gli ambienti sono i problemi di cui gli agenti razionali rappresentano le soluzioni\n",
    "- definire i **PEAS** (Performance, Environment, Actuators, Sensors) per ogni tipo di agente razionale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78520a1e",
   "metadata": {},
   "source": [
    "![image.png](images/environments.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2077514",
   "metadata": {},
   "source": [
    "- proprietà degli ambienti:\n",
    "    - **completamente osservabile vs. parzialmente osservabile**: **completamente osservabile** quando i sensori danno accesso allo stato completo dell'ambiente in ogni momento, o almeno che misurino gli aspetti rilevanti. **Parzialmente osservabile** se i sensori sono inaccurati, presenza di rumore o alcuni dati rilevanti non vengono catturati da essi\n",
    "    - **agente singolo vs. multiagente**: **agente singolo**, **multiagente competitivo** o **multiagente cooperativo**\n",
    "    - **deterministico vs. stocastico**: **deterministico** se lo stato successivo dell'ambiente è completamente determinato dallo stato corrente e dall'azione eseguita dall'agente. Altrimenti è **stocastico**\n",
    "    - **episodico vs. sequenziale**: **episodico** quando l'esperienza dell'agente è divisa in episodi atomici, ogni episodio non dipende dalle azioni intraprese in quelli precedenti. **Sequenziale** quando ogni decisione può influenzare tutte quelle successive\n",
    "    - **statico vs. dinamico**: **dinamico** se l'ambiente può cambiare mentre un agente sta pensando altrimenti è **statico**. **Semidinamico** se l'ambiente non cambia con il passare del tempo, ma la valutazione dell'agente si\n",
    "    - **discreto vs. continuo**: ci si riferisce al modo in cui è gestito il tempo\n",
    "    - **noto vs. ignoto**: ci si riferisce alla conoscenza che ha l'agente circa le \"leggi fisiche\" dell'ambiente. In un ambiente **noto** sono conosciuti i risultati per tutte le azioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d997b",
   "metadata": {},
   "source": [
    "![image.png](images/environments_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfbe325",
   "metadata": {},
   "source": [
    "### Rappresentazione degli stati e transizioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7fc75d",
   "metadata": {},
   "source": [
    "**rappresentazione atomica**: ogni stato del mondo è indivisibile, non ha struttura interna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b7a88f",
   "metadata": {},
   "source": [
    "![image.png](images/atomic_state.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17a8fe3",
   "metadata": {},
   "source": [
    "**rappresentazione fattorizzata**: suddivide ogni stato in un insieme fissato di variabili o attributi, che possono essere booleani, numeri reali, ...\n",
    "\n",
    "Si può rappresentare l'incertezza lasciando vuoto l'attributo corrispondente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bed285",
   "metadata": {},
   "source": [
    "![image.png](images/factored_state.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e281a96",
   "metadata": {},
   "source": [
    "**rappresentazione strutturata**: include oggetti, ognuno dei quali può avere attributi propri oltre a relazioni con altri oggetti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3cc189",
   "metadata": {},
   "source": [
    "![image.png](images/structured_state.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79789bd8",
   "metadata": {},
   "source": [
    "## Risolvere problemi con la ricerca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286447ef",
   "metadata": {},
   "source": [
    "- metodi utilizzabili da:\n",
    "    - **tipo agente**: **basato su obiettivi**\n",
    "    - **rappresentazione**: **atomica**\n",
    "    - **ambiente**:\n",
    "        - **completamente osservabile** (stato iniziale conosciuto)\n",
    "        - **deterministico** (non si possono gestire eventi inaspettati)\n",
    "        - **statico**\n",
    "        - **completamente noto**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835745d9",
   "metadata": {},
   "source": [
    "**algoritmo di ricerca**: prende un problema come input e restituisce una soluzione sotto forma di sequenza di azioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed37d60",
   "metadata": {},
   "source": [
    "- l'agente svolge ciclicamente i seguenti passi:\n",
    "    1. formula un obiettivo\n",
    "    2. formula un problema da risolvere\n",
    "    3. invoca una procedura di ricerca\n",
    "    4. esegue la sequenza di azioni restituita dalla procedura di ricerca, mentre la esegue vengono ignorate le percezioni, poichè le conosce in anticipo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4737381",
   "metadata": {},
   "source": [
    "![image.png](images/simple_problem_solving_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26649e2a",
   "metadata": {},
   "source": [
    "### Definizione dei problemi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ad044",
   "metadata": {},
   "source": [
    "- un **problema** è definito da:\n",
    "    - **stato iniziale**: in cui si trova l'agente\n",
    "    - **azioni possibili** dell'agente: dato uno stato $s$, $Azioni(s)$ restituisce l'insieme di azioni che possono essere eseguite in $s$\n",
    "    - **modello di transizione**: descrizione di ciò che ogni azione fa. $Risultato(s, \\alpha)$ restituisce lo stato risultante dall'esecuzione dell'azione $\\alpha$ nello stato $s$\n",
    "    - **test obiettivo**: funzione che verifica se uno stato è l'obiettivo\n",
    "    - **costo cammino**: assegna un costo numerico ad ogni cammino. Costo di passo $c(s, \\alpha, s')$: costo che dell'azione $\\alpha$ che fa passare lo stato $s$ ad $s'$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95871b72",
   "metadata": {},
   "source": [
    "**soluzione**: è una sequenza di azioni che porta dallo stato iniziale ad uno stato obiettivo. La sua qualità è in funzione del costo di cammino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82f4c7",
   "metadata": {},
   "source": [
    "### Cercare soluzioni"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
